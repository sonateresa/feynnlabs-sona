# -*- coding: utf-8 -*-
"""Sustainable Palette Prototype.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kd-FVCPxGoVHTkbD5uJksAjZA1-KC4yi
"""

import pandas as pd

food_production_df = pd.read_csv("/content/Food_Production.csv")
nutritional_info_df = pd.read_csv("/content/NUTRITIONAL INFO.csv")

print("Food Production Dataset - Missing Values:")
print(food_production_df.isnull().sum())
print("\nNutritional Info Dataset - Missing Values:")
print(nutritional_info_df.isnull().sum())

food_production_df.fillna(0, inplace=True)

print("Food Production Dataset - Missing Values:")
print(food_production_df.isnull().sum())

food_production_df.columns = food_production_df.columns.str.lower()
nutritional_info_df.columns = nutritional_info_df.columns.str.lower()

print("\nFood Production dataset:")
food_production_df.head()

print("\nNutritional Info dataset:")
nutritional_info_df.head()

#Step 2: Feature Engineering

#Calculate energy value per kilogram for nutritional info dataset
nutritional_info_df['energy_per_kg'] = nutritional_info_df['energy value(kcal)'] / 900  # Assuming 1 kilogram = 900 grams

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

print(nutritional_info_df.dtypes)

print(nutritional_info_df['total fat(g)'].unique())
print(nutritional_info_df['saturated fat(g)'].unique())
print(nutritional_info_df['trans fat(g)'].unique())

nutritional_info_df['total fat(g)'] = nutritional_info_df['total fat(g)'].replace('Trace', 0)
nutritional_info_df['saturated fat(g)'] = nutritional_info_df['saturated fat(g)'].replace(['Less than15%', 'Not more than 45.45'], 0)
nutritional_info_df['trans fat(g)'] = nutritional_info_df['trans fat(g)'].replace('Less than 1%', 0)

# Normalize numerical features in both datasets
food_production_df_normalized = food_production_df.copy()
food_production_df_normalized[['land use change', 'animal feed', 'farm', 'processing', 'transport', 'packging',
                               'retail', 'total_emissions']] = scaler.fit_transform(food_production_df[['land use change',
                                                                                                     'animal feed', 'farm',
                                                                                                     'processing',
                                                                                                     'transport', 'packging',
                                                                                                     'retail',
                                                                                                     'total_emissions']])

nutritional_info_df_normalized = nutritional_info_df.copy()
nutritional_info_df_normalized[['energy value(kcal)', 'protein(g)', 'carbohydrate(g)', 'total sugars(g)',
                                'added sugars(g)', 'total fat(g)', 'saturated fat(g)', 'trans fat(g)',
                                'cholesterol(mg)', 'sodium(mg)', 'energy_per_kg']] = scaler.fit_transform(
    nutritional_info_df[['energy value(kcal)', 'protein(g)', 'carbohydrate(g)', 'total sugars(g)', 'added sugars(g)',
                         'total fat(g)', 'saturated fat(g)', 'trans fat(g)', 'cholesterol(mg)', 'sodium(mg)',
                         'energy_per_kg']])

# Display the first few rows of normalized datasets to verify changes
print("\nNormalized Food Production dataset:")
print(food_production_df_normalized.head())

print("\nNormalized Nutritional Info dataset:")
print(nutritional_info_df_normalized.head())

#Step 3: Machine Learning Model Training

from sklearn.model_selection import train_test_split

# Assuming 'total_emissions' from food_production_df as the target variable
X = nutritional_info_df[['energy value(kcal)', 'protein(g)', 'carbohydrate(g)', 'total sugars(g)',
                          'added sugars(g)', 'total fat(g)', 'saturated fat(g)', 'trans fat(g)',
                          'cholesterol(mg)', 'sodium(mg)']]
y = food_production_df['total_emissions']

# Splitting the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Initialize regression models
linear_reg_model = LinearRegression()
random_forest_reg_model = RandomForestRegressor()
gradient_boosting_reg_model = GradientBoostingRegressor()

linear_reg_model.fit(X_train, y_train)

random_forest_reg_model.fit(X_train, y_train)

gradient_boosting_reg_model.fit(X_train, y_train)

linear_reg_predictions = linear_reg_model.predict(X_test)
random_forest_reg_predictions = random_forest_reg_model.predict(X_test)
gradient_boosting_reg_predictions = gradient_boosting_reg_model.predict(X_test)

# Evaluate the models
linear_reg_mse = mean_squared_error(y_test, linear_reg_predictions)
linear_reg_r2 = r2_score(y_test, linear_reg_predictions)

rf_reg_mse = mean_squared_error(y_test, random_forest_reg_predictions)
rf_reg_r2 = r2_score(y_test, random_forest_reg_predictions)

gb_reg_mse = mean_squared_error(y_test, gradient_boosting_reg_predictions)
gb_reg_r2 = r2_score(y_test, gradient_boosting_reg_predictions)

print("Linear Regression - MSE:", linear_reg_mse, "R-squared:", linear_reg_r2)
print("Random Forest Regression - MSE:", rf_reg_mse, "R-squared:", rf_reg_r2)
print("Gradient Boosting Regression - MSE:", gb_reg_mse, "R-squared:", gb_reg_r2)

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

print(nutritional_info_df.columns)

X = nutritional_info_df.drop(columns=['food product'])

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Determining the optimal number of clusters using the Elbow method
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

# Plotting the Elbow curve
plt.plot(range(1, 11), wcss)
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()

# Based on the Elbow curve, choose 5 clusters
kmeans = KMeans(n_clusters=5, init='k-means++', random_state=42)
clusters = kmeans.fit_predict(X_scaled)

nutritional_info_df['Cluster'] = clusters

cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)
cluster_centers_df = pd.DataFrame(cluster_centers, columns=X.columns)
print("Cluster Centers:")
print(cluster_centers_df)

# Visualizing the clusters
plt.figure(figsize=(10, 6))
plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap='viridis')
plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], s=300, c='red', marker='X', label='Centroids')
plt.title('Clusters of Food Products')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# Apply PCA to reduce the dimensionality of the data to 2 dimensions
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# Plot the clusters
plt.figure(figsize=(10, 8))
for i in range(len(cluster_centers)):
    plt.scatter(X_pca[kmeans.labels_ == i, 0], X_pca[kmeans.labels_ == i, 1], label=f'Cluster {i}', alpha=0.7)

# Add legend with cluster labels
plt.legend(title='Cluster Labels')

plt.title('Cluster Visualization using PCA')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()

# Plot cluster centers
plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], c='black', marker='x', s=100, label='Cluster Centers')

plt.title('Cluster Visualization using PCA')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend()
plt.show()

def assign_cluster_labels(data, kmeans_model):
    """Assign cluster labels to each data point"""
    cluster_labels = kmeans_model.predict(data)
    return cluster_labels

def recommend_products(product_name, cluster_labels, products_df):
    """Recommend other products from the same cluster as the given product"""
    product_cluster = cluster_labels[products_df.index[products_df['food product'] == product_name].tolist()[0]]
    recommended_products = products_df[cluster_labels == product_cluster]['food product']
    recommended_products = recommended_products[recommended_products != product_name]  # Exclude the given product
    return recommended_products

# Example
product_name = 'Parle Monaco Biscuits'
kmeans_model = KMeans(n_clusters=5, random_state=42)
kmeans_model.fit(X)
cluster_labels = kmeans_model.predict(X)
recommended_products = recommend_products(product_name, cluster_labels, nutritional_info_df)
print(f"Recommended products for '{product_name}':")
print(recommended_products)

product_name = 'Parle-G Biscuits'
kmeans_model = KMeans(n_clusters=5, random_state=42)
kmeans_model.fit(X)
cluster_labels = kmeans_model.predict(X)
recommended_products = recommend_products(product_name, cluster_labels, nutritional_info_df)
print(f"Recommended products for '{product_name}':")
print(recommended_products)

product_name = 'Aashirvaad ATTA'
kmeans_model = KMeans(n_clusters=5, random_state=42)
kmeans_model.fit(X)
cluster_labels = kmeans_model.predict(X)
recommended_products = recommend_products(product_name, cluster_labels, nutritional_info_df)
print(f"Recommended products for '{product_name}':")
print(recommended_products)

# Fit the KMeans model
kmeans_model.fit(X)

# Assign cluster labels to each data point
cluster_labels = assign_cluster_labels(X_scaled, kmeans_model)

# Add cluster labels to the nutritional_info_df
nutritional_info_df['Cluster'] = cluster_labels

# Display the dataframe with cluster labels
print(nutritional_info_df.head())

# Grouping by food type and summing up the total emissions
food_emissions = food_production_df.groupby('food product')['total_emissions'].sum()

# Sorting the emissions in descending order to find the most impactful food types
food_emissions_sorted = food_emissions.sort_values(ascending=False)

# Plotting the top 10 most impactful food types
top_10_food_emissions = food_emissions_sorted.head(10)
top_10_food_emissions.plot(kind='bar', figsize=(10, 6), color='skyblue')
plt.title('Top 10 Food Types with Highest Total Emissions')
plt.xlabel('Food Type')
plt.ylabel('Total Emissions')
plt.xticks(rotation=45)
plt.show()

# Calculate the average nutritional values for each food product
avg_nutritional_values = nutritional_info_df.groupby('food product')['protein(g)', 'energy value(kcal)'].mean()

# Plotting the average nutritional values
avg_nutritional_values.plot(kind='bar', figsize=(10, 6))
plt.title('Average Nutritional Values by Food Product')
plt.xlabel('Food Product')
plt.ylabel('Average Value')
plt.xticks(rotation=45)
plt.legend(["Protein (g)", "Energy (kcal)"])
plt.show()

print(food_production_df.columns)

print(nutritional_info_df.columns)

# Grouping by land use change of production and summing up the emissions
land_use_emissions = food_production_df.groupby('land use change')['total_emissions'].sum()

# Plotting the emissions by land use change of production
land_use_emissions.plot(kind='pie', autopct='%1.1f%%', figsize=(8, 8))
plt.title('Distribution of Greenhouse Gas Emissions by Land Use Change of Production')
plt.ylabel('')
plt.show()

# Grouping by farm of production and summing up the emissions
farm_emissions = food_production_df.groupby('farm')['total_emissions'].sum()

# Plotting the emissions by farm of production
farm_emissions.plot(kind='pie', autopct='%1.1f%%', figsize=(8, 8))
plt.title('Distribution of Greenhouse Gas Emissions by Farm of Production')
plt.ylabel('')
plt.show()

data = {
    'Food Product': ['Britannia 50-50 Biscuits', 'Parle Monaco Biscuits', 'Priya Gongura Pickle', 'Visakha Dairy Ganga Milk', 'HALDIRAM MOONG DAL', 'GRB GHEE'],
    'Total Emissions': [100, 200, 50, 80, 150, 300],
    'Food Type': ['Plant-based', 'Plant-based', 'Plant-based', 'Animal-based', 'Protein-rich', 'Animal-based']
}

df = pd.DataFrame(data)

avg_emissions = df.groupby('Food Type')['Total Emissions'].mean().sort_values()

# Plotting the comparison
avg_emissions.plot(kind='bar', color=['green', 'blue', 'red'])
plt.title('Comparison of Average Emissions by Food Category')
plt.xlabel('Food Category')
plt.ylabel('Average Emissions')
plt.show()

import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# Apply PCA to reduce the dimensionality of the data to 2 dimensions
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# Plot the clusters
plt.figure(figsize=(10, 8))
for i in range(len(cluster_centers)):
    plt.scatter(X_pca[kmeans.labels_ == i, 0], X_pca[kmeans.labels_ == i, 1], label=f'Cluster {i}', alpha=0.7)

# Plot cluster centers
plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], c='black', marker='x', s=100, label='Cluster Centers')

plt.title('Cluster Visualization using PCA')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend()
plt.show()

# Plotting nutritional value vs. total emissions
plt.figure(figsize=(10, 6))
plt.scatter(nutritional_info_df_normalized['protein(g)'], food_production_df_normalized['total_emissions'], label='Protein', alpha=0.7)
plt.scatter(nutritional_info_df_normalized['energy value(kcal)'], food_production_df_normalized['total_emissions'], label='Energy', alpha=0.7)
plt.title('Nutritional Value vs. Total Emissions')
plt.xlabel('Nutritional Value')
plt.ylabel('Total Emissions')
plt.legend()
plt.show()

import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(nutritional_info_df['protein(g)'], bins=20, kde=True, color='skyblue')
plt.title('Distribution of Protein Content')
plt.xlabel('Protein (g)')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(nutritional_info_df['energy value(kcal)'], bins=20, kde=True, color='salmon')
plt.title('Distribution of Energy Value')
plt.xlabel('Energy Value (kcal)')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(food_production_df['total_emissions'], bins=20, kde=True, color='lightgreen')
plt.title('Distribution of Total Emissions')
plt.xlabel('Total Emissions')
plt.ylabel('Frequency')
plt.show()

# Selecting a subset of columns for pairplot
pairplot_columns = ['protein(g)', 'energy value(kcal)', 'total fat(g)', 'carbohydrate(g)', 'total sugars(g)']

# Creating a pairplot
sns.pairplot(nutritional_info_df[pairplot_columns])
plt.suptitle('Pairplot of Nutritional Components', y=1.02)
plt.show()

plt.figure(figsize=(12, 8))
sns.heatmap(food_production_df.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='Food Type', y='Total Emissions', palette='pastel')
plt.title('Distribution of Emissions by Food Type')
plt.xlabel('Food Type')
plt.ylabel('Total Emissions')
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(10, 6))
sns.barplot(data=nutritional_info_df, x='Cluster', y='protein(g)', palette='Set2')
plt.title('Average Protein Content by Cluster')
plt.xlabel('Cluster')
plt.ylabel('Average Protein (g)')
plt.show()

plt.figure(figsize=(10, 6))
sns.violinplot(data=nutritional_info_df, x='Cluster', y='protein(g)', palette='husl')
plt.title('Protein Content Distribution by Cluster')
plt.xlabel('Cluster')
plt.ylabel('Protein (g)')
plt.show()